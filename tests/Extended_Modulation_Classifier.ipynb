{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ml_wireless_classification.base.AdvancedFeatureExtractor import AdvancedFeatureExtractor\n",
    "\n",
    "# Global dictionary to store feature names and values\n",
    "feature_dict = {}\n",
    "\n",
    "def add_feature(name, func, *args):\n",
    "    \"\"\"Try to add a feature by checking the shape and ensuring itâ€™s a scalar, array, or tuple with valid content.\"\"\"\n",
    "    try:\n",
    "        value = func(*args)\n",
    "        \n",
    "        # Check for scalar\n",
    "        if np.isscalar(value):\n",
    "            feature_dict[name] = value\n",
    "        # Check for single-element numpy array\n",
    "        elif isinstance(value, np.ndarray) and value.size == 1:\n",
    "            feature_dict[name] = value.item()\n",
    "        # Handle numpy arrays and tuples with multiple values\n",
    "        elif isinstance(value, (np.ndarray, tuple)):\n",
    "            if len(value) == 0:\n",
    "                print(f\"Warning: Feature '{name}' returned an empty array/tuple and was not added.\")\n",
    "            else:\n",
    "                for i, sub_value in enumerate(value):\n",
    "                    feature_dict[f\"{name}_{i}\"] = sub_value\n",
    "        # Check if it's a list with valid content\n",
    "        elif isinstance(value, list):\n",
    "            if len(value) == 0:\n",
    "                print(f\"Warning: Feature '{name}' returned an empty list and was not added.\")\n",
    "            else:\n",
    "                for i, sub_value in enumerate(value):\n",
    "                    feature_dict[f\"{name}_{i}\"] = sub_value\n",
    "        else:\n",
    "            print(f\"Warning: Feature '{name}' has an unexpected shape/type and was not added.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing feature '{name}': {e}\")\n",
    "\n",
    "def extract_features(data):\n",
    "    features = []\n",
    "    labels = []\n",
    "    snrs = []\n",
    "    # Instantiate AdvancedFeatureExtractor with the complex signal\n",
    "    feature_extractor = AdvancedFeatureExtractor(np.zeros(128))\n",
    "    # Retrieve feature methods and names\n",
    "    feature_methods = feature_extractor.get_features()\n",
    "    \n",
    "    for key, signals in data.items():\n",
    "        mod_type, snr = key\n",
    "        for signal in signals:\n",
    "            real_part, imag_part = signal[0], signal[1]\n",
    "            complex_signal = real_part + 1j * imag_part\n",
    "            feature_extractor.set_signal(complex_signal)\n",
    "\n",
    "            # Reset the global feature dictionary\n",
    "            global feature_dict\n",
    "            feature_dict = {}\n",
    "\n",
    "            # Loop through each feature and add it using the add_feature function\n",
    "            for feature_name, feature_func in feature_methods.items():\n",
    "                add_feature(feature_name, feature_func)\n",
    "\n",
    "            # Add SNR as a feature\n",
    "            feature_dict[\"SNR\"] = snr  # Include SNR as part of the features\n",
    "\n",
    "            # Append the feature values and label\n",
    "            features.append(list(feature_dict.values()))\n",
    "            labels.append(mod_type)\n",
    "\n",
    "    return np.array(features), labels\n",
    "\n",
    "# Load the RML2016.10a_dict.pkl file with explicit encoding\n",
    "with open(\"../RML2016.10a_dict.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f, encoding=\"latin1\")\n",
    "\n",
    "# Feature extraction for all signals\n",
    "features, labels = extract_features(data)\n",
    "\n",
    "# Encode labels for classification\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, encoded_labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a single classifier on the entire dataset for multi-class classification\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "print(\"Training...\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate accuracy for each SNR level\n",
    "unique_snrs = sorted(set(X_test[:, -1]))  # Get unique SNR levels from test set\n",
    "accuracy_per_snr = []\n",
    "\n",
    "for snr in unique_snrs:\n",
    "    # Select samples with the current SNR\n",
    "    snr_indices = np.where(X_test[:, -1] == snr)\n",
    "    X_snr = X_test[snr_indices]\n",
    "    y_snr = y_test[snr_indices]\n",
    "\n",
    "    # Predict and calculate accuracy\n",
    "    y_pred = clf.predict(X_snr)\n",
    "    accuracy = accuracy_score(y_snr, y_pred)\n",
    "    accuracy_per_snr.append(accuracy * 100)  # Convert to percentage\n",
    "\n",
    "    print(f\"SNR: {snr} dB, Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Plot Recognition Accuracy vs. SNR\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(unique_snrs, accuracy_per_snr, 'b-o', label='Recognition Accuracy')\n",
    "plt.xlabel(\"SNR (dB)\")\n",
    "plt.ylabel(\"Recognition Accuracy (%)\")\n",
    "plt.title(\"Recognition Accuracy vs. SNR for Modulation Classification\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.ylim(0, 100)\n",
    "plt.show()\n",
    "\n",
    "# Feature importance for the classifier\n",
    "feature_names = list(feature_dict.keys())\n",
    "importances = clf.feature_importances_\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(feature_names, importances, color='skyblue')\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"Feature Importance for Modulation Classification\")\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix for overall test set\n",
    "y_pred_test = clf.predict(X_test)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix for Multi-Class Modulation Classification\")\n",
    "plt.show()\n",
    "\n",
    "# Print Classification Report\n",
    "print(\"Classification Report for Modulation Types:\")\n",
    "print(classification_report(y_test, y_pred_test, target_names=label_encoder.classes_))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

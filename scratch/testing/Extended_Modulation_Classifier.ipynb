{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ml_wireless_classification.base.AdvancedFeatureExtractor import AdvancedFeatureExtractor\n",
    "\n",
    "# Global dictionary to store feature names and values\n",
    "feature_dict = {}\n",
    "\n",
    "def add_feature(name, func, *args):\n",
    "    \"\"\"Try to add a feature by ensuring itâ€™s a scalar or individual elements if an array, tuple, or list.\"\"\"\n",
    "    try:\n",
    "        value = func(*args)\n",
    "\n",
    "        if np.isscalar(value):\n",
    "            # Add directly if it's a scalar\n",
    "            if np.iscomplex(value):  # Check if scalar is complex\n",
    "                feature_dict[f\"{name}_magnitude\"] = np.abs(value)\n",
    "                feature_dict[f\"{name}_phase\"] = np.angle(value)\n",
    "            else:\n",
    "                feature_dict[name] = value\n",
    "        elif isinstance(value, (np.ndarray, list, tuple)):\n",
    "            # Flatten and iterate over each element if it's an array, list, or tuple\n",
    "            flattened_values = np.ravel(value)\n",
    "            for i, sub_value in enumerate(flattened_values):\n",
    "                if np.isscalar(sub_value):  # Ensure sub_value is scalar\n",
    "                    if np.iscomplex(sub_value):\n",
    "                        feature_dict[f\"{name}_{i}_magnitude\"] = np.abs(sub_value)\n",
    "                        feature_dict[f\"{name}_{i}_phase\"] = np.angle(sub_value)\n",
    "                    else:\n",
    "                        feature_dict[f\"{name}_{i}\"] = sub_value\n",
    "                else:\n",
    "                    print(f\"Warning: Non-scalar value found in '{name}_{i}' and was not added.\")\n",
    "        else:\n",
    "            print(f\"Warning: Feature '{name}' has unsupported type {type(value)} and was not added.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing feature '{name}': {e}\")\n",
    "\n",
    "def extract_features(data):\n",
    "    features = []\n",
    "    labels = []\n",
    "    snrs = []\n",
    "    # Instantiate AdvancedFeatureExtractor with the complex signal\n",
    "    feature_extractor = AdvancedFeatureExtractor(np.zeros(128))\n",
    "    # Retrieve feature methods and names\n",
    "    feature_methods = feature_extractor.get_features()\n",
    "    \n",
    "    for key, signals in data.items():\n",
    "        mod_type, snr = key\n",
    "        for signal in signals:\n",
    "            real_part, imag_part = signal[0], signal[1]\n",
    "            complex_signal = real_part + 1j * imag_part\n",
    "            feature_extractor.set_signal(complex_signal)\n",
    "\n",
    "            # Reset the global feature dictionary\n",
    "            global feature_dict\n",
    "            feature_dict = {}\n",
    "\n",
    "            # Loop through each feature and add it using the add_feature function\n",
    "            for feature_name, feature_func in feature_methods.items():\n",
    "                add_feature(feature_name, feature_func)\n",
    "\n",
    "            # Add SNR as a feature\n",
    "            feature_dict[\"SNR\"] = snr  # Include SNR as part of the features\n",
    "\n",
    "            # Append the feature values and label\n",
    "            features.append(list(feature_dict.values()))\n",
    "            labels.append(mod_type)\n",
    "\n",
    "    return np.array(features), labels\n",
    "\n",
    "\n",
    "# Load the RML2016.10a_dict.pkl file with explicit encoding\n",
    "with open(\"../RML2016.10a_dict.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f, encoding=\"latin1\")\n",
    "\n",
    "# Feature extraction for all signals\n",
    "features, labels = extract_features(data)\n",
    "\n",
    "# Encode labels for classification\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, encoded_labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a single classifier on the entire dataset for multi-class classification\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# print(\"Training...\")\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate accuracy for each SNR level\n",
    "# unique_snrs = sorted(set(X_test[:, -1]))  # Get unique SNR levels from test set\n",
    "# accuracy_per_snr = []\n",
    "\n",
    "# for snr in unique_snrs:\n",
    "#     # Select samples with the current SNR\n",
    "#     snr_indices = np.where(X_test[:, -1] == snr)\n",
    "#     X_snr = X_test[snr_indices]\n",
    "#     y_snr = y_test[snr_indices]\n",
    "\n",
    "#     # Predict and calculate accuracy\n",
    "#     y_pred = clf.predict(X_snr)\n",
    "#     accuracy = accuracy_score(y_snr, y_pred)\n",
    "#     accuracy_per_snr.append(accuracy * 100)  # Convert to percentage\n",
    "\n",
    "#     print(f\"SNR: {snr} dB, Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# # Plot Recognition Accuracy vs. SNR\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(unique_snrs, accuracy_per_snr, 'b-o', label='Recognition Accuracy')\n",
    "# plt.xlabel(\"SNR (dB)\")\n",
    "# plt.ylabel(\"Recognition Accuracy (%)\")\n",
    "# plt.title(\"Recognition Accuracy vs. SNR for Modulation Classification\")\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.ylim(0, 100)\n",
    "# plt.show()\n",
    "\n",
    "# # Feature importance for the classifier\n",
    "# feature_names = list(feature_dict.keys())\n",
    "# importances = clf.feature_importances_\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.barh(feature_names, importances, color='skyblue')\n",
    "# plt.xlabel(\"Feature Importance\")\n",
    "# plt.title(\"Feature Importance for Modulation Classification\")\n",
    "# plt.show()\n",
    "\n",
    "# # Confusion matrix for overall test set\n",
    "# y_pred_test = clf.predict(X_test)\n",
    "# conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "# plt.figure(figsize=(12, 10))\n",
    "# sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "#             xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "# plt.xlabel(\"Predicted Label\")\n",
    "# plt.ylabel(\"True Label\")\n",
    "# plt.title(\"Confusion Matrix for Multi-Class Modulation Classification\")\n",
    "# plt.show()\n",
    "\n",
    "# # Print Classification Report\n",
    "# print(\"Classification Report for Modulation Types:\")\n",
    "# print(classification_report(y_test, y_pred_test, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_training_data(X, y):\n",
    "    \"\"\"\n",
    "    Cleans X and y by ensuring that all elements are scalars and removing infinities.\n",
    "    Prints a message if a sequence (list, tuple, array) or non-numeric value is found.\n",
    "    \"\"\"\n",
    "    def check_and_clean_array(arr, array_name):\n",
    "        cleaned_arr = []\n",
    "        for i, row in enumerate(arr):\n",
    "            cleaned_row = []\n",
    "            for j, value in enumerate(row):\n",
    "                # Check if value is scalar\n",
    "                if np.isscalar(value):\n",
    "                    # Check for infinities or non-finite values\n",
    "                    if np.isinf(value) or np.isnan(value) or value > np.finfo(np.float32).max:\n",
    "                        print(f\"Warning: {array_name}[{i}][{j}] has an infinity or too large value. Setting to 0.\")\n",
    "                        cleaned_row.append(0)  # Replace infinities or overly large values with 0\n",
    "                    else:\n",
    "                        cleaned_row.append(value)\n",
    "                elif isinstance(value, (list, tuple, np.ndarray)):\n",
    "                    # If it's a sequence, take the first element as a workaround (optional)\n",
    "                    sub_value = value[0] if len(value) > 0 else 0\n",
    "                    if np.isinf(sub_value) or np.isnan(sub_value) or sub_value > np.finfo(np.float32).max:\n",
    "                        print(f\"Warning: {array_name}[{i}][{j}] contains infinity or too large in sequence. Setting to 0.\")\n",
    "                        sub_value = 0\n",
    "                    cleaned_row.append(sub_value)\n",
    "                    print(f\"Warning: {array_name}[{i}][{j}] is a sequence. Taking the first element.\")\n",
    "                elif isinstance(value, str):\n",
    "                    # Handle string values with a warning\n",
    "                    print(f\"Warning: {array_name}[{i}][{j}] is a string. Removing and setting to 0.\")\n",
    "                    cleaned_row.append(0)\n",
    "                else:\n",
    "                    print(f\"Warning: Unexpected data type at {array_name}[{i}][{j}]: {type(value)}\")\n",
    "                    cleaned_row.append(0)  # Default to 0 if type is unexpected\n",
    "            cleaned_arr.append(cleaned_row)\n",
    "        \n",
    "        # Ensure cleaned_arr is a 2D array of fixed-length rows\n",
    "        max_length = max(len(row) for row in cleaned_arr)\n",
    "        # Pad rows with zeros if they are shorter than max_length\n",
    "        cleaned_arr = [row + [0] * (max_length - len(row)) for row in cleaned_arr]\n",
    "        \n",
    "        return np.array(cleaned_arr, dtype=float)\n",
    "    \n",
    "    # Clean X and y\n",
    "    X_cleaned = check_and_clean_array(X, \"X_train\")\n",
    "    y_cleaned = np.array([elem if np.isscalar(elem) else elem[0] for elem in y], dtype=float)\n",
    "\n",
    "    return X_cleaned, y_cleaned\n",
    "\n",
    "def ensure_2d(arr, name):\n",
    "    \"\"\"\n",
    "    Ensures the array is 2D by reshaping if necessary.\n",
    "    \"\"\"\n",
    "    if arr.ndim == 1:\n",
    "        print(f\"Warning: {name} is 1-dimensional. Reshaping to 2D.\")\n",
    "        arr = arr.reshape(-1, 1)\n",
    "    return arr\n",
    "\n",
    "# Clean training and test data\n",
    "X_train, y_train = clean_training_data(X_train, y_train)\n",
    "X_test, y_test = clean_training_data(X_test, y_test)\n",
    "\n",
    "# Ensure both X_train and X_test are 2D arrays\n",
    "X_train = ensure_2d(X_train, \"X_train\")\n",
    "X_test = ensure_2d(X_test, \"X_test\")\n",
    "\n",
    "print(\"Training...\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Check if SNR is actually included as a feature\n",
    "if X_test.ndim > 1 and X_test.shape[1] > 1:\n",
    "    # Evaluate accuracy for each SNR level if the SNR column is present\n",
    "    unique_snrs = sorted(set(X_test[:, -1]))  # Get unique SNR levels from test set\n",
    "    accuracy_per_snr = []\n",
    "\n",
    "    for snr in unique_snrs:\n",
    "        # Select samples with the current SNR\n",
    "        snr_indices = np.where(X_test[:, -1] == snr)\n",
    "        X_snr = X_test[snr_indices]\n",
    "        y_snr = y_test[snr_indices]\n",
    "\n",
    "        # Predict and calculate accuracy\n",
    "        y_pred = clf.predict(X_snr)\n",
    "        accuracy = accuracy_score(y_snr, y_pred)\n",
    "        accuracy_per_snr.append(accuracy * 100)  # Convert to percentage\n",
    "\n",
    "        print(f\"SNR: {snr} dB, Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Plot Recognition Accuracy vs. SNR\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(unique_snrs, accuracy_per_snr, 'b-o', label='Recognition Accuracy')\n",
    "    plt.xlabel(\"SNR (dB)\")\n",
    "    plt.ylabel(\"Recognition Accuracy (%)\")\n",
    "    plt.title(\"Recognition Accuracy vs. SNR for Modulation Classification\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.ylim(0, 100)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"SNR feature not found in X_test; skipping SNR-based evaluation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for the classifier\n",
    "feature_names = list(feature_dict.keys())\n",
    "importances = clf.feature_importances_\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "sorted_indices = np.argsort(importances)[::-1]\n",
    "sorted_feature_names = [feature_names[i] for i in sorted_indices]\n",
    "sorted_importances = importances[sorted_indices]\n",
    "\n",
    "# Plot sorted feature importances\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(sorted_feature_names, sorted_importances, color='skyblue')\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"Feature Importance for Modulation Classification\")\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to show the highest importance at the top\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix for overall test set\n",
    "y_pred_test = clf.predict(X_test)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix for Multi-Class Modulation Classification\")\n",
    "plt.show()\n",
    "\n",
    "# Print Classification Report\n",
    "print(\"Classification Report for Modulation Types:\")\n",
    "print(classification_report(y_test, y_pred_test, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance (if using a tree-based model)\n",
    "# Plot confusion matrix for SNR > 5 dB subset\n",
    "\n",
    "# Assuming SNR values are in the last column of X_test\n",
    "snr_column_index = -1  # Adjust this if SNR is in a different column\n",
    "\n",
    "# Find indices where SNR > 5\n",
    "snr_above_5_indices = np.where(X_test[:, snr_column_index] > 5)[0]\n",
    "X_test_snr_above_5 = X_test[snr_above_5_indices]\n",
    "y_test_snr_above_5 = y_test[snr_above_5_indices]\n",
    "\n",
    "# Make predictions on the SNR > 5 dB subset\n",
    "y_pred_snr_above_5 = clf.predict(X_test_snr_above_5)\n",
    "\n",
    "# Plot confusion matrix for SNR > 5 dB\n",
    "conf_matrix_snr_above_5 = confusion_matrix(y_test_snr_above_5, y_pred_snr_above_5)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(conf_matrix_snr_above_5, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix for Modulation Classification (SNR > 5 dB)\")\n",
    "plt.show()\n",
    "\n",
    "# Print the classification report for SNR > 5 dB\n",
    "print(\"Classification Report for Modulation Types (SNR > 5 dB):\")\n",
    "print(classification_report(y_test_snr_above_5, y_pred_snr_above_5, target_names=label_encoder.classes_))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

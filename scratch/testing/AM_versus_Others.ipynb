{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ml_wireless_classification.base.SignalUtils import (\n",
    "    compute_instantaneous_features, compute_modulation_index, compute_spectral_asymmetry,\n",
    "    instantaneous_frequency_deviation, spectral_entropy, envelope_mean_variance,\n",
    "    spectral_flatness, spectral_peaks_bandwidth, zero_crossing_rate, compute_fft_features,\n",
    "    autocorrelation, is_digital_signal, compute_kurtosis, compute_skewness,\n",
    "    compute_spectral_energy_concentration, compute_instantaneous_frequency_jitter,\n",
    "    compute_spectral_kurtosis, compute_higher_order_cumulants, compute_crest_factor,\n",
    "    compute_spectral_entropy, compute_energy_spread, compute_autocorrelation_decay,\n",
    "    compute_rms_of_instantaneous_frequency, compute_entropy_of_instantaneous_frequency,\n",
    "    compute_envelope_variance, compute_papr\n",
    ")\n",
    "\n",
    "# Global dictionary to store feature names and values\n",
    "feature_dict = {}\n",
    "\n",
    "def add_feature(name, func, *args):\n",
    "    \"\"\"Try to add a feature by checking the shape and ensuring it’s a scalar.\"\"\"\n",
    "    try:\n",
    "        value = func(*args)\n",
    "        # If value is an array, check if it is scalar (single value)\n",
    "        if np.isscalar(value) or (isinstance(value, np.ndarray) and value.size == 1):\n",
    "            feature_dict[name] = value.item() if isinstance(value, np.ndarray) else value\n",
    "        else:\n",
    "            print(f\"Warning: Feature '{name}' has incorrect shape and was not added.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing feature '{name}': {e}\")\n",
    "\n",
    "def extract_features(data):\n",
    "    features = []\n",
    "    labels = []\n",
    "    snrs = []\n",
    "\n",
    "    for key, signals in data.items():\n",
    "        mod_type, snr = key\n",
    "        for signal in signals:\n",
    "            real_part, imag_part = signal[0], signal[1]\n",
    "            complex_signal = real_part + 1j * imag_part\n",
    "\n",
    "            # Reset feature dictionary for each signal\n",
    "            global feature_dict\n",
    "            feature_dict = {}\n",
    "\n",
    "            # Add features with validation\n",
    "            add_feature(\"Inst. Freq. Dev\", instantaneous_frequency_deviation, complex_signal)\n",
    "            add_feature(\"Spectral Entropy\", spectral_entropy, real_part)\n",
    "            add_feature(\"Envelope Mean\", lambda x: envelope_mean_variance(x)[0], real_part)\n",
    "            add_feature(\"Envelope Variance\", lambda x: envelope_mean_variance(x)[1], real_part)\n",
    "            add_feature(\"Spectral Flatness\", spectral_flatness, real_part)\n",
    "            add_feature(\"Spectral Peaks\", lambda x: spectral_peaks_bandwidth(x)[0], real_part)\n",
    "            add_feature(\"Bandwidth\", lambda x: spectral_peaks_bandwidth(x)[1], real_part)\n",
    "            add_feature(\"Zero Crossing Rate\", zero_crossing_rate, real_part)\n",
    "            add_feature(\"Amplitude Mean\", lambda x: np.mean(compute_instantaneous_features(x)[0]), real_part)\n",
    "            add_feature(\"Phase Variance\", lambda x: np.var(compute_instantaneous_features(x)[1]), real_part)\n",
    "            add_feature(\"Modulation Index\", compute_modulation_index, real_part)\n",
    "            add_feature(\"Spectral Sparsity\", compute_spectral_asymmetry, real_part)\n",
    "            add_feature(\"Envelope Ratio\", lambda x: envelope_mean_variance(x)[0] / (envelope_mean_variance(x)[1] + 1e-10), real_part)\n",
    "            add_feature(\"FFT Center Freq\", lambda x: compute_fft_features(x)[0], real_part)\n",
    "            add_feature(\"FFT Peak Power\", lambda x: compute_fft_features(x)[1], real_part)\n",
    "            add_feature(\"FFT Avg Power\", lambda x: compute_fft_features(x)[2], real_part)\n",
    "            add_feature(\"FFT Std Dev Power\", lambda x: compute_fft_features(x)[3], real_part)\n",
    "            add_feature(\"Kurtosis\", compute_kurtosis, real_part)\n",
    "            add_feature(\"Skewness\", compute_skewness, real_part)\n",
    "            add_feature(\"HOC-2\", lambda x: compute_higher_order_cumulants(x, order=2), real_part)\n",
    "            add_feature(\"HOC-3\", lambda x: compute_higher_order_cumulants(x, order=3), real_part)\n",
    "            add_feature(\"HOC-4\", lambda x: compute_higher_order_cumulants(x, order=4), real_part)\n",
    "            add_feature(\"Crest Factor\", compute_crest_factor, real_part)\n",
    "            add_feature(\"Spectral Entropy Value\", compute_spectral_entropy, real_part)\n",
    "            add_feature(\"Autocorr Decay\", compute_autocorrelation_decay, real_part)\n",
    "            add_feature(\"RMS Instant Freq\", compute_rms_of_instantaneous_frequency, real_part)\n",
    "            add_feature(\"Entropy Instant Freq\", compute_entropy_of_instantaneous_frequency, real_part)\n",
    "            add_feature(\"Envelope Variance\", compute_envelope_variance, real_part)\n",
    "            add_feature(\"PAPR\", compute_papr, real_part)\n",
    "\n",
    "            # Add SNR as a feature\n",
    "            feature_dict[\"SNR\"] = snr  # Include SNR as part of the features\n",
    "\n",
    "            # Append the feature values and label\n",
    "            features.append(list(feature_dict.values()))\n",
    "            labels.append(mod_type)\n",
    "\n",
    "    return np.array(features), labels\n",
    "\n",
    "# Load the RML2016.10a_dict.pkl file with explicit encoding\n",
    "with open(\"../RML2016.10a_dict.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f, encoding=\"latin1\")\n",
    "\n",
    "# Feature extraction for all signals\n",
    "features, labels = extract_features(data)\n",
    "\n",
    "# Encode labels for classification\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, encoded_labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a single classifier on the entire dataset\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate accuracy for each SNR level\n",
    "unique_snrs = sorted(set(X_test[:, -1]))  # Get unique SNR levels from test set\n",
    "accuracy_per_snr = []\n",
    "\n",
    "for snr in unique_snrs:\n",
    "    # Select samples with the current SNR\n",
    "    snr_indices = np.where(X_test[:, -1] == snr)\n",
    "    X_snr = X_test[snr_indices]\n",
    "    y_snr = y_test[snr_indices]\n",
    "\n",
    "    # Predict and calculate accuracy\n",
    "    y_pred = clf.predict(X_snr)\n",
    "    accuracy = accuracy_score(y_snr, y_pred)\n",
    "    accuracy_per_snr.append(accuracy * 100)  # Convert to percentage\n",
    "\n",
    "    print(f\"SNR: {snr} dB, Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Plot Recognition Accuracy vs. SNR\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(unique_snrs, accuracy_per_snr, 'b-o', label='Recognition Accuracy')\n",
    "plt.xlabel(\"SNR (dB)\")\n",
    "plt.ylabel(\"Recognition Accuracy (%)\")\n",
    "plt.title(\"Recognition Accuracy vs. SNR\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.ylim(0, 100)\n",
    "plt.show()\n",
    "\n",
    "# Feature importance for the classifier\n",
    "feature_names = list(feature_dict.keys())\n",
    "importances = clf.feature_importances_\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(feature_names, importances, color='skyblue')\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"Feature Importance for Classification\")\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix for overall test set\n",
    "y_pred_test = clf.predict(X_test)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix for Modulation Classification\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# denoise and filter with a second method\n",
    "\n",
    "from scipy.signal import butter, sosfilt\n",
    "import pywt\n",
    "\n",
    "def apply_bandpass_filter(signal, lowcut, highcut, fs, order=5):\n",
    "    sos = butter(order, [lowcut, highcut], btype='band', fs=fs, output='sos')\n",
    "    return sosfilt(sos, signal)\n",
    "\n",
    "def wavelet_denoising(signal, wavelet='db1', level=2):\n",
    "    coeffs = pywt.wavedec(signal, wavelet, level=level)\n",
    "    thresholded_coeffs = [pywt.threshold(c, np.std(c), mode='soft') for c in coeffs]\n",
    "    return pywt.waverec(thresholded_coeffs, wavelet)\n",
    "\n",
    "def extract_features_with_filtering(data, fs=2.5, lowcut=0.1, highcut=2.5):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for key, signals in data.items():\n",
    "        mod_type, snr = key\n",
    "        for signal in signals:\n",
    "            real_part, imag_part = signal[0], signal[1]\n",
    "            \n",
    "            # Apply Bandpass Filter\n",
    "            filtered_real = apply_bandpass_filter(real_part, lowcut, highcut, fs)\n",
    "            filtered_imag = apply_bandpass_filter(imag_part, lowcut, highcut, fs)\n",
    "\n",
    "            # Apply Wavelet Denoising\n",
    "            real_denoised = wavelet_denoising(filtered_real)\n",
    "            imag_denoised = wavelet_denoising(filtered_imag)\n",
    "            complex_denoised_signal = real_denoised + 1j * imag_denoised\n",
    "\n",
    "            # Reset feature dictionary for each signal\n",
    "            global feature_dict\n",
    "            feature_dict = {}\n",
    "\n",
    "            # Add features with validation\n",
    "            add_feature(\"Inst. Freq. Dev\", instantaneous_frequency_deviation, complex_denoised_signal)\n",
    "            add_feature(\"Spectral Entropy\", spectral_entropy, real_denoised)\n",
    "            add_feature(\"Envelope Mean\", lambda x: envelope_mean_variance(x)[0], real_denoised)\n",
    "            add_feature(\"Envelope Variance\", lambda x: envelope_mean_variance(x)[1], real_denoised)\n",
    "            add_feature(\"Spectral Flatness\", spectral_flatness, real_denoised)\n",
    "            add_feature(\"Spectral Peaks\", lambda x: spectral_peaks_bandwidth(x)[0], real_denoised)\n",
    "            add_feature(\"Bandwidth\", lambda x: spectral_peaks_bandwidth(x)[1], real_denoised)\n",
    "            add_feature(\"Zero Crossing Rate\", zero_crossing_rate, real_denoised)\n",
    "            add_feature(\"Amplitude Mean\", lambda x: np.mean(compute_instantaneous_features(x)[0]), real_denoised)\n",
    "            add_feature(\"Phase Variance\", lambda x: np.var(compute_instantaneous_features(x)[1]), real_denoised)\n",
    "            add_feature(\"Modulation Index\", compute_modulation_index, real_denoised)\n",
    "            add_feature(\"Spectral Sparsity\", compute_spectral_asymmetry, real_denoised)\n",
    "            add_feature(\"Envelope Ratio\", lambda x: envelope_mean_variance(x)[0] / (envelope_mean_variance(x)[1] + 1e-10), real_denoised)\n",
    "            add_feature(\"FFT Center Freq\", lambda x: compute_fft_features(x)[0], real_denoised)\n",
    "            add_feature(\"FFT Peak Power\", lambda x: compute_fft_features(x)[1], real_denoised)\n",
    "            add_feature(\"FFT Avg Power\", lambda x: compute_fft_features(x)[2], real_denoised)\n",
    "            add_feature(\"FFT Std Dev Power\", lambda x: compute_fft_features(x)[3], real_denoised)\n",
    "            add_feature(\"Kurtosis\", compute_kurtosis, real_denoised)\n",
    "            add_feature(\"Skewness\", compute_skewness, real_denoised)\n",
    "            add_feature(\"HOC-2\", lambda x: compute_higher_order_cumulants(x, order=2), real_denoised)\n",
    "            add_feature(\"HOC-3\", lambda x: compute_higher_order_cumulants(x, order=3), real_denoised)\n",
    "            add_feature(\"HOC-4\", lambda x: compute_higher_order_cumulants(x, order=4), real_denoised)\n",
    "            add_feature(\"Crest Factor\", compute_crest_factor, real_denoised)\n",
    "            add_feature(\"Spectral Entropy Value\", compute_spectral_entropy, real_denoised)\n",
    "            add_feature(\"Autocorr Decay\", compute_autocorrelation_decay, real_denoised)\n",
    "            add_feature(\"RMS Instant Freq\", compute_rms_of_instantaneous_frequency, real_denoised)\n",
    "            add_feature(\"Entropy Instant Freq\", compute_entropy_of_instantaneous_frequency, real_denoised)\n",
    "            add_feature(\"Envelope Variance\", compute_envelope_variance, real_denoised)\n",
    "            add_feature(\"PAPR\", compute_papr, real_denoised)\n",
    "\n",
    "            # Add SNR as a feature\n",
    "            feature_dict[\"SNR\"] = snr  # Include SNR as part of the features\n",
    "\n",
    "            # Append the feature values and label\n",
    "            features.append(list(feature_dict.values()))\n",
    "            labels.append(mod_type)\n",
    "\n",
    "    return np.array(features), labels\n",
    "\n",
    "# Apply the new feature extraction with filtering\n",
    "filtered_features, filtered_labels = extract_features_with_filtering(data)\n",
    "\n",
    "# Encode labels for classification\n",
    "filtered_encoded_labels = label_encoder.fit_transform(filtered_labels)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train_filtered, X_test_filtered, y_train_filtered, y_test_filtered = train_test_split(\n",
    "    filtered_features, filtered_encoded_labels, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train a classifier on the filtered data\n",
    "clf_filtered = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_filtered.fit(X_train_filtered, y_train_filtered)\n",
    "\n",
    "# Evaluate accuracy for each SNR level with filtered data\n",
    "accuracy_per_snr_filtered = []\n",
    "for snr in unique_snrs:\n",
    "    snr_indices_filtered = np.where(X_test_filtered[:, -1] == snr)\n",
    "    X_snr_filtered = X_test_filtered[snr_indices_filtered]\n",
    "    y_snr_filtered = y_test_filtered[snr_indices_filtered]\n",
    "\n",
    "    # Predict and calculate accuracy\n",
    "    y_pred_filtered = clf_filtered.predict(X_snr_filtered)\n",
    "    accuracy = accuracy_score(y_snr_filtered, y_pred_filtered)\n",
    "    accuracy_per_snr_filtered.append(accuracy * 100)\n",
    "\n",
    "    print(f\"SNR: {snr} dB, Accuracy (filtered): {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Plot Comparison of Recognition Accuracy vs. SNR\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(unique_snrs, accuracy_per_snr, 'b-o', label='Original Recognition Accuracy')\n",
    "plt.plot(unique_snrs, accuracy_per_snr_filtered, 'g-o', label='Filtered Recognition Accuracy')\n",
    "plt.xlabel(\"SNR (dB)\")\n",
    "plt.ylabel(\"Recognition Accuracy (%)\")\n",
    "plt.title(\"Recognition Accuracy vs. SNR (Original vs. Filtered)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.ylim(0, 100)\n",
    "plt.show()\n",
    "\n",
    "# Feature importance for the filtered classifier\n",
    "importances_filtered = clf_filtered.feature_importances_\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(feature_names, importances_filtered, color='skyblue')\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"Feature Importance for Filtered Classification\")\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix for filtered test set\n",
    "y_pred_test_filtered = clf_filtered.predict(X_test_filtered)\n",
    "conf_matrix_filtered = confusion_matrix(y_test_filtered, y_pred_test_filtered)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(conf_matrix_filtered, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix for Filtered Modulation Classification\")\n",
    "plt.show()\n",
    "\n",
    "# Print Classification Report for filtered data\n",
    "print(\"Classification Report for Filtered Modulation Types:\")\n",
    "print(classification_report(y_test_filtered, y_pred_test_filtered, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.signal import butter, sosfilt, medfilt\n",
    "import pywt\n",
    "from ml_wireless_classification.base.SignalUtils import (\n",
    "    compute_instantaneous_features, compute_modulation_index, compute_spectral_asymmetry,\n",
    "    instantaneous_frequency_deviation, spectral_entropy, envelope_mean_variance,\n",
    "    spectral_flatness, spectral_peaks_bandwidth, zero_crossing_rate, compute_fft_features,\n",
    "    autocorrelation, is_digital_signal, compute_kurtosis, compute_skewness,\n",
    "    compute_spectral_energy_concentration, compute_instantaneous_frequency_jitter,\n",
    "    compute_spectral_kurtosis, compute_higher_order_cumulants, compute_crest_factor,\n",
    "    compute_spectral_entropy, compute_energy_spread, compute_autocorrelation_decay,\n",
    "    compute_rms_of_instantaneous_frequency, compute_entropy_of_instantaneous_frequency,\n",
    "    compute_envelope_variance, compute_papr\n",
    ")\n",
    "\n",
    "# Filtering functions\n",
    "def apply_bandpass_filter(signal, lowcut, highcut, fs, order=5):\n",
    "    sos = butter(order, [lowcut, highcut], btype='band', fs=fs, output='sos')\n",
    "    return sosfilt(sos, signal)\n",
    "\n",
    "def apply_median_filter(signal, kernel_size=5):\n",
    "    return medfilt(signal, kernel_size=kernel_size)\n",
    "\n",
    "def apply_wavelet_denoising(signal, wavelet=\"db1\", level=1):\n",
    "    coeffs = pywt.wavedec(signal, wavelet, mode=\"soft\")\n",
    "    threshold = np.median(np.abs(coeffs[-level])) / 0.6745\n",
    "    denoised_coeffs = [pywt.threshold(c, threshold, mode=\"soft\") for c in coeffs]\n",
    "    return pywt.waverec(denoised_coeffs, wavelet)\n",
    "\n",
    "# Combined filtering function\n",
    "def preprocess_signal(signal, fs, lowcut=0.5, highcut=40, kernel_size=5, wavelet=\"db1\", level=1):\n",
    "    # Step 1: Bandpass filter\n",
    "    filtered_signal = apply_bandpass_filter(signal, lowcut, highcut, fs)\n",
    "    # Step 2: Median filter\n",
    "    median_filtered_signal = apply_median_filter(filtered_signal, kernel_size)\n",
    "    # Step 3: Wavelet denoising\n",
    "    denoised_signal = apply_wavelet_denoising(median_filtered_signal, wavelet, level)\n",
    "    return denoised_signal\n",
    "\n",
    "# Global dictionary to store feature names and values\n",
    "feature_dict = {}\n",
    "\n",
    "def add_feature(name, func, *args):\n",
    "    \"\"\"Try to add a feature by checking the shape and ensuring it’s a scalar.\"\"\"\n",
    "    try:\n",
    "        value = func(*args)\n",
    "        if np.isscalar(value) or (isinstance(value, np.ndarray) and value.size == 1):\n",
    "            feature_dict[name] = value.item() if isinstance(value, np.ndarray) else value\n",
    "        else:\n",
    "            print(f\"Warning: Feature '{name}' has incorrect shape and was not added.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing feature '{name}': {e}\")\n",
    "\n",
    "def extract_features(data, fs=100):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for key, signals in data.items():\n",
    "        mod_type, snr = key\n",
    "        for signal in signals:\n",
    "            real_part, imag_part = signal[0], signal[1]\n",
    "            # Apply preprocessing to real and imaginary parts\n",
    "            real_part = preprocess_signal(real_part, fs)\n",
    "            imag_part = preprocess_signal(imag_part, fs)\n",
    "            complex_signal = real_part + 1j * imag_part\n",
    "\n",
    "            # Reset feature dictionary for each signal\n",
    "            global feature_dict\n",
    "            feature_dict = {}\n",
    "\n",
    "            # Add features with validation\n",
    "            add_feature(\"Inst. Freq. Dev\", instantaneous_frequency_deviation, complex_signal)\n",
    "            add_feature(\"Spectral Entropy\", spectral_entropy, real_part)\n",
    "            add_feature(\"Envelope Mean\", lambda x: envelope_mean_variance(x)[0], real_part)\n",
    "            add_feature(\"Envelope Variance\", lambda x: envelope_mean_variance(x)[1], real_part)\n",
    "            add_feature(\"Spectral Flatness\", spectral_flatness, real_part)\n",
    "            add_feature(\"Spectral Peaks\", lambda x: spectral_peaks_bandwidth(x)[0], real_part)\n",
    "            add_feature(\"Bandwidth\", lambda x: spectral_peaks_bandwidth(x)[1], real_part)\n",
    "            add_feature(\"Zero Crossing Rate\", zero_crossing_rate, real_part)\n",
    "            add_feature(\"Amplitude Mean\", lambda x: np.mean(compute_instantaneous_features(x)[0]), real_part)\n",
    "            add_feature(\"Phase Variance\", lambda x: np.var(compute_instantaneous_features(x)[1]), real_part)\n",
    "            add_feature(\"Modulation Index\", compute_modulation_index, real_part)\n",
    "            add_feature(\"Spectral Sparsity\", compute_spectral_asymmetry, real_part)\n",
    "            add_feature(\"Envelope Ratio\", lambda x: envelope_mean_variance(x)[0] / (envelope_mean_variance(x)[1] + 1e-10), real_part)\n",
    "            add_feature(\"FFT Center Freq\", lambda x: compute_fft_features(x)[0], real_part)\n",
    "            add_feature(\"FFT Peak Power\", lambda x: compute_fft_features(x)[1], real_part)\n",
    "            add_feature(\"FFT Avg Power\", lambda x: compute_fft_features(x)[2], real_part)\n",
    "            add_feature(\"FFT Std Dev Power\", lambda x: compute_fft_features(x)[3], real_part)\n",
    "            add_feature(\"Kurtosis\", compute_kurtosis, real_part)\n",
    "            add_feature(\"Skewness\", compute_skewness, real_part)\n",
    "            add_feature(\"HOC-2\", lambda x: compute_higher_order_cumulants(x, order=2), real_part)\n",
    "            add_feature(\"HOC-3\", lambda x: compute_higher_order_cumulants(x, order=3), real_part)\n",
    "            add_feature(\"HOC-4\", lambda x: compute_higher_order_cumulants(x, order=4), real_part)\n",
    "            add_feature(\"Crest Factor\", compute_crest_factor, real_part)\n",
    "            add_feature(\"Spectral Entropy Value\", compute_spectral_entropy, real_part)\n",
    "            add_feature(\"Autocorr Decay\", compute_autocorrelation_decay, real_part)\n",
    "            add_feature(\"RMS Instant Freq\", compute_rms_of_instantaneous_frequency, real_part)\n",
    "            add_feature(\"Entropy Instant Freq\", compute_entropy_of_instantaneous_frequency, real_part)\n",
    "            add_feature(\"Envelope Variance\", compute_envelope_variance, real_part)\n",
    "            add_feature(\"PAPR\", compute_papr, real_part)\n",
    "\n",
    "            # Add SNR as a feature\n",
    "            feature_dict[\"SNR\"] = snr  # Include SNR as part of the features\n",
    "\n",
    "            # Append the feature values and label\n",
    "            features.append(list(feature_dict.values()))\n",
    "            labels.append(mod_type)\n",
    "\n",
    "    return np.array(features), labels\n",
    "\n",
    "# Load and preprocess data\n",
    "with open(\"../RML2016.10a_dict.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f, encoding=\"latin1\")\n",
    "\n",
    "features, labels = extract_features(data)\n",
    "\n",
    "# Encode labels for classification\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Train/test split and classification\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, encoded_labels, test_size=0.3, random_state=42)\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model by SNR and plot results\n",
    "unique_snrs = sorted(set(X_test[:, -1]))\n",
    "accuracy_per_snr = []\n",
    "for snr in unique_snrs:\n",
    "    snr_indices = np.where(X_test[:, -1] == snr)\n",
    "    X_snr = X_test[snr_indices]\n",
    "    y_snr = y_test[snr_indices]\n",
    "    y_pred = clf.predict(X_snr)\n",
    "    accuracy = accuracy_score(y_snr, y_pred)\n",
    "    accuracy_per_snr.append(accuracy * 100)\n",
    "    print(f\"SNR: {snr} dB, Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Plot Recognition Accuracy vs. SNR\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(unique_snrs, accuracy_per_snr, 'b-o', label='Recognition Accuracy')\n",
    "plt.xlabel(\"SNR (dB)\")\n",
    "plt.ylabel(\"Recognition Accuracy (%)\")\n",
    "plt.title(\"Recognition Accuracy vs. SNR with Preprocessing\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.ylim(0, 100)\n",
    "plt.show()\n",
    "\n",
    "# Feature importance plot\n",
    "feature_names = list(feature_dict.keys())\n",
    "importances = clf.feature_importances_\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(feature_names, importances, color='skyblue')\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"Feature Importance for Modulation Classification with Preprocessing\")\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix\n",
    "y_pred_test = clf.predict(X_test)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix for Modulation Classification with Preprocessing\")\n",
    "plt.show()\n",
    "\n",
    "# Print Classification Report\n",
    "print(\"Classification Report for Modulation Types with Preprocessing:\")\n",
    "print(classification_report(y_test, y_pred_test, target_names=label_encoder.classes_))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

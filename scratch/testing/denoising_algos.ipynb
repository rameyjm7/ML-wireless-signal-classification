{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter, medfilt\n",
    "from pywt import wavedec, waverec, threshold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Global dictionary to store feature names and values\n",
    "feature_dict = {}\n",
    "\n",
    "def add_feature(name, func, *args):\n",
    "    \"\"\"Try to add a feature by checking the shape and ensuring it’s a scalar.\"\"\"\n",
    "    try:\n",
    "        value = func(*args)\n",
    "        if np.isscalar(value):\n",
    "            feature_dict[name] = value\n",
    "        elif isinstance(value, (list, tuple, np.ndarray)) and value.size == 1:\n",
    "            feature_dict[name] = value.item()\n",
    "        else:\n",
    "            print(f\"Warning: Feature '{name}' has incorrect shape and was not added.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing feature '{name}': {e}\")\n",
    "\n",
    "# Denoising algorithms\n",
    "def wavelet_denoise(signal, wavelet='db1', level=1, thresholding='soft'):\n",
    "    coeffs = wavedec(signal, wavelet, level=level)\n",
    "    coeffs[1:] = [threshold(c, np.median(np.abs(c)) / 0.6745, mode=thresholding) for c in coeffs[1:]]\n",
    "    return waverec(coeffs, wavelet)\n",
    "\n",
    "def fourier_denoise(signal, cutoff_freq):\n",
    "    fft_signal = np.fft.fft(signal)\n",
    "    freqs = np.fft.fftfreq(len(signal))\n",
    "    fft_signal[np.abs(freqs) > cutoff_freq] = 0\n",
    "    return np.fft.ifft(fft_signal).real\n",
    "\n",
    "def savgol_denoise(signal, window_length=5, polyorder=2):\n",
    "    return savgol_filter(signal, window_length, polyorder)\n",
    "\n",
    "def median_denoise(signal, kernel_size=3):\n",
    "    return medfilt(signal, kernel_size)\n",
    "\n",
    "def moving_average_denoise(signal, window_size=5):\n",
    "    return np.convolve(signal, np.ones(window_size) / window_size, mode='same')\n",
    "\n",
    "# Apply denoising and extract features\n",
    "def apply_denoising_and_extract_features(data, denoise_func, *denoise_args):\n",
    "    features = []\n",
    "    labels = []\n",
    "    snrs = []\n",
    "    \n",
    "    for key, signals in data.items():\n",
    "        mod_type, snr = key\n",
    "        for signal in signals:\n",
    "            real_part, imag_part = signal[0], signal[1]\n",
    "            \n",
    "            # Apply denoising to real and imaginary parts separately\n",
    "            real_denoised = denoise_func(real_part, *denoise_args)\n",
    "            imag_denoised = denoise_func(imag_part, *denoise_args)\n",
    "            \n",
    "            # Combine real and imaginary into magnitude and phase\n",
    "            magnitude = np.sqrt(real_denoised**2 + imag_denoised**2)\n",
    "            phase = np.arctan2(imag_denoised, real_denoised)\n",
    "            \n",
    "            # Reset feature dictionary for each signal\n",
    "            global feature_dict\n",
    "            feature_dict = {}\n",
    "\n",
    "            # Add features using magnitude and phase\n",
    "            add_feature(\"Magnitude Mean\", np.mean, magnitude)\n",
    "            add_feature(\"Magnitude Variance\", np.var, magnitude)\n",
    "            add_feature(\"Phase Mean\", np.mean, phase)\n",
    "            add_feature(\"Phase Variance\", np.var, phase)\n",
    "            add_feature(\"Real Part Mean\", np.mean, real_denoised)\n",
    "            add_feature(\"Imag Part Mean\", np.mean, imag_denoised)\n",
    "            add_feature(\"Real Part Variance\", np.var, real_denoised)\n",
    "            add_feature(\"Imag Part Variance\", np.var, imag_denoised)\n",
    "\n",
    "            # Add SNR as a feature\n",
    "            feature_dict[\"SNR\"] = snr  # Include SNR as part of the features\n",
    "\n",
    "            # Append the feature values and label\n",
    "            features.append(list(feature_dict.values()))\n",
    "            labels.append(mod_type)\n",
    "\n",
    "    return np.array(features), labels\n",
    "\n",
    "# Load the RML2016.10a_dict.pkl file with explicit encoding\n",
    "with open(\"../RML2016.10a_dict.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f, encoding=\"latin1\")\n",
    "\n",
    "# Denoising methods to test\n",
    "denoise_methods = {\n",
    "    \"Wavelet Denoising\": (wavelet_denoise, ('db1', 1, 'soft')),\n",
    "    \"Fourier Denoising\": (fourier_denoise, (0.1,)),\n",
    "    \"Savitzky-Golay Filter\": (savgol_denoise, (5, 2)),\n",
    "    \"Median Filter\": (median_denoise, (3,)),\n",
    "    \"Moving Average Filter\": (moving_average_denoise, (5,))\n",
    "}\n",
    "\n",
    "# Train and evaluate classifier for each denoising method\n",
    "for method_name, (denoise_func, denoise_args) in denoise_methods.items():\n",
    "    print(f\"\\nEvaluating {method_name}\")\n",
    "    \n",
    "    # Extract features using denoising\n",
    "    features, labels = apply_denoising_and_extract_features(data, denoise_func, *denoise_args)\n",
    "    \n",
    "    # Encode labels for classification\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_labels = label_encoder.fit_transform(labels)\n",
    "    \n",
    "    # Split dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, encoded_labels, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Train classifier\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate accuracy\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy with {method_name}: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Plot confusion matrix for each method\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "                xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(f\"Confusion Matrix for {method_name}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter, medfilt, wiener\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Global dictionary to store feature names and values\n",
    "feature_dict = {}\n",
    "\n",
    "def add_feature(name, func, *args):\n",
    "    \"\"\"Try to add a feature by checking the shape and ensuring it’s a scalar.\"\"\"\n",
    "    try:\n",
    "        value = func(*args)\n",
    "        if np.isscalar(value):\n",
    "            feature_dict[name] = value\n",
    "        elif isinstance(value, (list, tuple, np.ndarray)) and value.size == 1:\n",
    "            feature_dict[name] = value.item()\n",
    "        else:\n",
    "            print(f\"Warning: Feature '{name}' has incorrect shape and was not added.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing feature '{name}': {e}\")\n",
    "\n",
    "# Denoising algorithms\n",
    "def ema_denoise(signal, alpha):\n",
    "    ema_signal = np.zeros_like(signal)\n",
    "    ema_signal[0] = signal[0]\n",
    "    for i in range(1, len(signal)):\n",
    "        ema_signal[i] = alpha * signal[i] + (1 - alpha) * ema_signal[i - 1]\n",
    "    return ema_signal\n",
    "\n",
    "def gaussian_denoise(signal, sigma):\n",
    "    return gaussian_filter1d(signal, sigma)\n",
    "\n",
    "def wiener_denoise(signal, mysize=5):\n",
    "    return wiener(signal, mysize)\n",
    "\n",
    "# Apply denoising and extract features\n",
    "def apply_denoising_and_extract_features(data, denoise_func, *denoise_args):\n",
    "    features = []\n",
    "    labels = []\n",
    "    snrs = []\n",
    "    \n",
    "    for key, signals in data.items():\n",
    "        mod_type, snr = key\n",
    "        for signal in signals:\n",
    "            real_part, imag_part = signal[0], signal[1]\n",
    "            \n",
    "            # Apply denoising to real and imaginary parts separately\n",
    "            real_denoised = denoise_func(real_part, *denoise_args)\n",
    "            imag_denoised = denoise_func(imag_part, *denoise_args)\n",
    "            \n",
    "            # Combine real and imaginary into magnitude and phase\n",
    "            magnitude = np.sqrt(real_denoised**2 + imag_denoised**2)\n",
    "            phase = np.arctan2(imag_denoised, real_denoised)\n",
    "            \n",
    "            # Reset feature dictionary for each signal\n",
    "            global feature_dict\n",
    "            feature_dict = {}\n",
    "\n",
    "            # Add features using magnitude and phase\n",
    "            add_feature(\"Magnitude Mean\", np.mean, magnitude)\n",
    "            add_feature(\"Magnitude Variance\", np.var, magnitude)\n",
    "            add_feature(\"Phase Mean\", np.mean, phase)\n",
    "            add_feature(\"Phase Variance\", np.var, phase)\n",
    "            add_feature(\"Real Part Mean\", np.mean, real_denoised)\n",
    "            add_feature(\"Imag Part Mean\", np.mean, imag_denoised)\n",
    "            add_feature(\"Real Part Variance\", np.var, real_denoised)\n",
    "            add_feature(\"Imag Part Variance\", np.var, imag_denoised)\n",
    "\n",
    "            # Add SNR as a feature\n",
    "            feature_dict[\"SNR\"] = snr  # Include SNR as part of the features\n",
    "\n",
    "            # Append the feature values and label\n",
    "            features.append(list(feature_dict.values()))\n",
    "            labels.append(mod_type)\n",
    "\n",
    "    return np.array(features), labels\n",
    "\n",
    "# Load the RML2016.10a_dict.pkl file with explicit encoding\n",
    "with open(\"../RML2016.10a_dict.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f, encoding=\"latin1\")\n",
    "\n",
    "# Denoising methods and parameter values to test\n",
    "denoise_methods = {\n",
    "    \"EMA Alpha=0.1\": (ema_denoise, (0.1,)),\n",
    "    \"EMA Alpha=0.3\": (ema_denoise, (0.3,)),\n",
    "    \"EMA Alpha=0.5\": (ema_denoise, (0.5,)),\n",
    "    \"Gaussian Sigma=1\": (gaussian_denoise, (1,)),\n",
    "    \"Gaussian Sigma=2\": (gaussian_denoise, (2,)),\n",
    "    \"Wiener Filter\": (wiener_denoise, (5,))\n",
    "}\n",
    "\n",
    "# Train and evaluate classifier for each denoising method\n",
    "for method_name, (denoise_func, denoise_args) in denoise_methods.items():\n",
    "    print(f\"\\nEvaluating {method_name}\")\n",
    "    \n",
    "    # Extract features using denoising\n",
    "    features, labels = apply_denoising_and_extract_features(data, denoise_func, *denoise_args)\n",
    "    \n",
    "    # Encode labels for classification\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_labels = label_encoder.fit_transform(labels)\n",
    "    \n",
    "    # Split dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, encoded_labels, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Train classifier\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate accuracy\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy with {method_name}: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Plot confusion matrix for each method\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "                xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(f\"Confusion Matrix for {method_name}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def moving_average_denoise(signal, window_size=10):\n",
    "    return np.convolve(signal, np.ones(window_size) / window_size, mode='same')\n",
    "\n",
    "# Denoising methods and parameter values to test\n",
    "denoise_methods = {\n",
    "    \"Moving Average Filter\": (moving_average_denoise, (10,))\n",
    "}\n",
    "\n",
    "# Train and evaluate classifier for each denoising method\n",
    "for method_name, (denoise_func, denoise_args) in denoise_methods.items():\n",
    "    print(f\"\\nEvaluating {method_name}\")\n",
    "    \n",
    "    # Extract features using denoising\n",
    "    features, labels = apply_denoising_and_extract_features(data, denoise_func, *denoise_args)\n",
    "    \n",
    "    # Encode labels for classification\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_labels = label_encoder.fit_transform(labels)\n",
    "    \n",
    "    # Split dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, encoded_labels, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Train classifier\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate accuracy\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy with {method_name}: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Plot confusion matrix for each method\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "                xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(f\"Confusion Matrix for {method_name}\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ml_wireless_classification.base.SignalUtils import (\n",
    "    compute_instantaneous_features, compute_modulation_index, compute_spectral_asymmetry,\n",
    "    instantaneous_frequency_deviation, spectral_entropy, envelope_mean_variance,\n",
    "    spectral_flatness, spectral_peaks_bandwidth, zero_crossing_rate, compute_fft_features,\n",
    "    autocorrelation, is_digital_signal, compute_kurtosis, compute_skewness,\n",
    "    compute_spectral_energy_concentration, compute_instantaneous_frequency_jitter,\n",
    "    compute_spectral_kurtosis, compute_higher_order_cumulants, compute_crest_factor,\n",
    "    compute_spectral_entropy, compute_energy_spread, compute_autocorrelation_decay,\n",
    "    compute_rms_of_instantaneous_frequency, compute_entropy_of_instantaneous_frequency,\n",
    "    compute_envelope_variance, compute_papr\n",
    ")\n",
    "from sklearn.metrics.pairwise import rbf_kernel, polynomial_kernel\n",
    "# Global dictionary to store feature names and values\n",
    "feature_dict = {}\n",
    "\n",
    "def add_feature(name, func, *args):\n",
    "    \"\"\"Try to add a feature by checking the shape and ensuring itâ€™s a scalar.\"\"\"\n",
    "    try:\n",
    "        value = func(*args)\n",
    "        if np.isscalar(value):\n",
    "            feature_dict[name] = value\n",
    "        elif isinstance(value, (list, tuple, np.ndarray)) and value.size == 1:\n",
    "            feature_dict[name] = value.item()\n",
    "        else:\n",
    "            print(f\"Warning: Feature '{name}' has incorrect shape and was not added.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing feature '{name}': {e}\")\n",
    "        \n",
    "\n",
    "def compute_kernel_transformed_features(signal, kernel_type='rbf', gamma=0.1, degree=2):\n",
    "    \"\"\"\n",
    "    Compute kernel-based features to help distinguish QAM levels.\n",
    "    \n",
    "    Parameters:\n",
    "    - signal: The input complex signal.\n",
    "    - kernel_type: Type of kernel to use ('rbf' or 'polynomial').\n",
    "    - gamma: Parameter for the RBF kernel.\n",
    "    - degree: Degree for the polynomial kernel.\n",
    "    \n",
    "    Returns:\n",
    "    - A scalar feature based on the chosen kernel.\n",
    "    \"\"\"\n",
    "    magnitudes = np.abs(signal)\n",
    "    distances = np.expand_dims(magnitudes, axis=1)  # Reshape for pairwise kernel computation\n",
    "    \n",
    "    if kernel_type == 'rbf':\n",
    "        kernel_matrix = rbf_kernel(distances, gamma=gamma)\n",
    "    elif kernel_type == 'polynomial':\n",
    "        kernel_matrix = polynomial_kernel(distances, degree=degree, gamma=gamma)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid kernel type. Choose 'rbf' or 'polynomial'.\")\n",
    "    \n",
    "    # Summarize kernel matrix into a scalar feature (e.g., mean or variance)\n",
    "    mean_kernel_value = np.mean(kernel_matrix)\n",
    "    variance_kernel_value = np.var(kernel_matrix)\n",
    "    \n",
    "    return mean_kernel_value, variance_kernel_value\n",
    "\n",
    "def extract_features(data):\n",
    "    features = []\n",
    "    labels = []\n",
    "    snrs = []\n",
    "    # Kernel parameters for RBF and polynomial kernels\n",
    "    rbf_gammas = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    poly_degrees = [3, 4, 5]\n",
    "    \n",
    "    for key, signals in data.items():\n",
    "        mod_type, snr = key\n",
    "        for signal in signals:\n",
    "            real_part, imag_part = signal[0], signal[1]\n",
    "            complex_signal = real_part + 1j * imag_part\n",
    "\n",
    "            # Reset feature dictionary for each signal\n",
    "            global feature_dict\n",
    "            feature_dict = {}\n",
    "\n",
    "            # # Add features with validation\n",
    "            add_feature(\"Inst. Freq. Dev\", instantaneous_frequency_deviation, complex_signal)\n",
    "            add_feature(\"Phase Variance\", lambda x: np.var(compute_instantaneous_features(x)[1]), real_part)\n",
    "            # # Additional features for QAM16 vs QAM64 separation\n",
    "            add_feature(\"Avg Symbol Power\", lambda x: np.mean(np.abs(x)**2), complex_signal)\n",
    "            add_feature(\"PAPR\", lambda x: np.max(np.abs(x)**2) / np.mean(np.abs(x)**2), complex_signal)\n",
    "            add_feature(\"Kurtosis Magnitude\", lambda x: compute_kurtosis(np.abs(x)), complex_signal)\n",
    "            add_feature(\"Skewness Magnitude\", lambda x: compute_skewness(np.abs(x)), complex_signal)\n",
    "\n",
    "            # Add kernel-based features for different RBF gamma values\n",
    "            for gamma in rbf_gammas:\n",
    "                mean_rbf, var_rbf = compute_kernel_transformed_features(complex_signal, kernel_type='rbf', gamma=gamma)\n",
    "                add_feature(f\"RBF Kernel Mean Gamma_{gamma}\", lambda: mean_rbf)\n",
    "                add_feature(f\"RBF Kernel Variance Gamma_{gamma}\", lambda: var_rbf)\n",
    "            \n",
    "            # Add kernel-based features for different polynomial degrees\n",
    "            for degree in poly_degrees:\n",
    "                mean_poly, var_poly = compute_kernel_transformed_features(complex_signal, kernel_type='polynomial', gamma=0.1, degree=degree)\n",
    "                add_feature(f\"Poly Kernel Mean Degree_{degree}\", lambda: mean_poly)\n",
    "                add_feature(f\"Poly Kernel Variance Degree_{degree}\", lambda: var_poly)\n",
    "\n",
    "\n",
    "            # Add SNR as a feature\n",
    "            feature_dict[\"SNR\"] = snr  # Include SNR as part of the features\n",
    "\n",
    "            # Append the feature values and label\n",
    "            features.append(list(feature_dict.values()))\n",
    "            labels.append(mod_type)\n",
    "\n",
    "    return np.array(features), labels\n",
    "\n",
    "# Load the RML2016.10a_dict.pkl file with explicit encoding\n",
    "with open(\"../RML2016.10a_dict.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f, encoding=\"latin1\")\n",
    "\n",
    "# Feature extraction for all signals\n",
    "features, labels = extract_features(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels for classification\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, encoded_labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a single classifier on the entire dataset\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate accuracy for each SNR level\n",
    "unique_snrs = sorted(set(X_test[:, -1]))  # Get unique SNR levels from test set\n",
    "accuracy_per_snr = []\n",
    "\n",
    "for snr in unique_snrs:\n",
    "    # Select samples with the current SNR\n",
    "    snr_indices = np.where(X_test[:, -1] == snr)\n",
    "    X_snr = X_test[snr_indices]\n",
    "    y_snr = y_test[snr_indices]\n",
    "\n",
    "    # Predict and calculate accuracy\n",
    "    y_pred = clf.predict(X_snr)\n",
    "    accuracy = accuracy_score(y_snr, y_pred)\n",
    "    accuracy_per_snr.append(accuracy * 100)  # Convert to percentage\n",
    "\n",
    "    print(f\"SNR: {snr} dB, Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Plot Recognition Accuracy vs. SNR\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(unique_snrs, accuracy_per_snr, 'b-o', label='Recognition Accuracy')\n",
    "plt.xlabel(\"SNR (dB)\")\n",
    "plt.ylabel(\"Recognition Accuracy (%)\")\n",
    "plt.title(\"Recognition Accuracy vs. SNR\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.ylim(0, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature importance for the classifier\n",
    "feature_names = list(feature_dict.keys())\n",
    "importances = clf.feature_importances_\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "sorted_indices = np.argsort(importances)[::-1]\n",
    "sorted_feature_names = [feature_names[i] for i in sorted_indices]\n",
    "sorted_importances = importances[sorted_indices]\n",
    "\n",
    "# Plot sorted feature importances\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(sorted_feature_names, sorted_importances, color='skyblue')\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"Feature Importance for Modulation Classification\")\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to show the highest importance at the top\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix for overall test set\n",
    "y_pred_test = clf.predict(X_test)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix for Multi-Class Modulation Classification\")\n",
    "plt.show()\n",
    "\n",
    "# Print Classification Report\n",
    "print(\"Classification Report for Modulation Types:\")\n",
    "print(classification_report(y_test, y_pred_test, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate accuracy for each SNR level\n",
    "unique_snrs = sorted(set(X_test[:, -1]))  # Get unique SNR levels from test set\n",
    "accuracy_per_snr = []\n",
    "\n",
    "for snr in unique_snrs:\n",
    "    # Select samples with the current SNR\n",
    "    snr_indices = np.where(X_test[:, -1] == snr)\n",
    "    X_snr = X_test[snr_indices]\n",
    "    y_snr = y_test[snr_indices]\n",
    "\n",
    "    # Predict and calculate accuracy\n",
    "    y_pred = clf.predict(X_snr)\n",
    "    accuracy = accuracy_score(y_snr, y_pred)\n",
    "    accuracy_per_snr.append(accuracy * 100)  # Convert to percentage\n",
    "\n",
    "    print(f\"SNR: {snr} dB, Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Plot Recognition Accuracy vs. SNR\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(unique_snrs, accuracy_per_snr, 'b-o', label='Recognition Accuracy')\n",
    "plt.xlabel(\"SNR (dB)\")\n",
    "plt.ylabel(\"Recognition Accuracy (%)\")\n",
    "plt.title(\"Recognition Accuracy vs. SNR for Modulation Classification\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.ylim(0, 100)\n",
    "plt.show()\n",
    "\n",
    "# Feature importance for the classifier\n",
    "feature_names = list(feature_dict.keys())\n",
    "importances = clf.feature_importances_\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(feature_names, importances, color='skyblue')\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"Feature Importance for Modulation Classification\")\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix for overall test set\n",
    "y_pred_test = clf.predict(X_test)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix for Multi-Class Modulation Classification\")\n",
    "plt.show()\n",
    "\n",
    "# Print Classification Report\n",
    "print(\"Classification Report for Modulation Types:\")\n",
    "print(classification_report(y_test, y_pred_test, target_names=label_encoder.classes_))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

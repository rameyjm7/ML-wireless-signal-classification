{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from ml_wireless_classification.RandomForestModulationClassifier import RandomForestModulationClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ml_wireless_classification.base.SignalUtils import (\n",
    "    compute_instantaneous_features, compute_modulation_index, compute_spectral_asymmetry,\n",
    "    instantaneous_frequency_deviation, spectral_entropy, envelope_mean_variance,\n",
    "    spectral_flatness, spectral_peaks_bandwidth, zero_crossing_rate, compute_fft_features,\n",
    "    autocorrelation, is_digital_signal, compute_kurtosis, compute_skewness,\n",
    "    compute_spectral_energy_concentration, compute_instantaneous_frequency_jitter,\n",
    "    compute_spectral_kurtosis, compute_higher_order_cumulants, compute_crest_factor,\n",
    "    compute_spectral_entropy, compute_energy_spread, compute_autocorrelation_decay,\n",
    "    compute_rms_of_instantaneous_frequency, compute_entropy_of_instantaneous_frequency,\n",
    "    compute_envelope_variance, compute_papr\n",
    ")\n",
    "\n",
    "# Initialize global dictionary to store feature names and values\n",
    "feature_dict = {}\n",
    "\n",
    "def add_feature(name, func, *args):\n",
    "    \"\"\"Add a feature by checking the shape and ensuring itâ€™s a scalar.\"\"\"\n",
    "    try:\n",
    "        value = func(*args)\n",
    "        if np.isscalar(value):\n",
    "            feature_dict[name] = value\n",
    "        elif isinstance(value, (np.ndarray, list, tuple)) and len(value) == 1:\n",
    "            feature_dict[name] = value[0]\n",
    "        else:\n",
    "            print(f\"Warning: Feature '{name}' has an unexpected shape or type and was not added.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing feature '{name}': {e}\")\n",
    "\n",
    "def extract_features(data):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for key, signals in data.items():\n",
    "        mod_type, snr = key\n",
    "        for signal in signals:\n",
    "            real_part, imag_part = signal[0], signal[1]\n",
    "            complex_signal = real_part + 1j * imag_part\n",
    "\n",
    "            # Reset feature dictionary for each signal\n",
    "            global feature_dict\n",
    "            feature_dict = {}\n",
    "\n",
    "            add_feature(\"Inst. Freq. Dev\", instantaneous_frequency_deviation, complex_signal)\n",
    "            # add_feature(\"Spectral Entropy\", spectral_entropy, real_part)\n",
    "            add_feature(\"Envelope Mean\", lambda x: envelope_mean_variance(x)[0], real_part)\n",
    "            # add_feature(\"Envelope Variance\", lambda x: envelope_mean_variance(x)[1], real_part)\n",
    "            # add_feature(\"Spectral Flatness\", spectral_flatness, real_part)\n",
    "            # add_feature(\"Spectral Peaks\", lambda x: spectral_peaks_bandwidth(x)[0], real_part)\n",
    "            # add_feature(\"Bandwidth\", lambda x: spectral_peaks_bandwidth(x)[1], real_part)\n",
    "            # add_feature(\"Zero Crossing Rate\", zero_crossing_rate, real_part)\n",
    "            add_feature(\"Amplitude Mean\", lambda x: np.mean(compute_instantaneous_features(x)[0]), real_part)\n",
    "            add_feature(\"Phase Variance\", lambda x: np.var(compute_instantaneous_features(x)[1]), real_part)\n",
    "            # add_feature(\"Modulation Index\", compute_modulation_index, real_part)\n",
    "            # add_feature(\"Spectral Sparsity\", compute_spectral_asymmetry, real_part)\n",
    "            # add_feature(\"Envelope Ratio\", lambda x: envelope_mean_variance(x)[0] / (envelope_mean_variance(x)[1] + 1e-10), real_part)\n",
    "            # add_feature(\"FFT Center Freq\", lambda x: compute_fft_features(x)[0], real_part)\n",
    "            # add_feature(\"FFT Peak Power\", lambda x: compute_fft_features(x)[1], real_part)\n",
    "            # add_feature(\"FFT Avg Power\", lambda x: compute_fft_features(x)[2], real_part)\n",
    "            # add_feature(\"FFT Std Dev Power\", lambda x: compute_fft_features(x)[3], real_part)\n",
    "            # add_feature(\"Kurtosis\", compute_kurtosis, real_part)\n",
    "            # add_feature(\"Skewness\", compute_skewness, real_part)\n",
    "            # add_feature(\"HOC-2\", lambda x: compute_higher_order_cumulants(x, order=2), real_part)\n",
    "            # add_feature(\"HOC-3\", lambda x: compute_higher_order_cumulants(x, order=3), real_part)\n",
    "            # add_feature(\"HOC-4\", lambda x: compute_higher_order_cumulants(x, order=4), real_part)\n",
    "            # add_feature(\"Crest Factor\", compute_crest_factor, real_part)\n",
    "            # add_feature(\"Spectral Entropy Value\", compute_spectral_entropy, real_part)\n",
    "            # add_feature(\"Autocorr Decay\", compute_autocorrelation_decay, real_part)\n",
    "            # add_feature(\"RMS Instant Freq\", compute_rms_of_instantaneous_frequency, real_part)\n",
    "            # add_feature(\"Entropy Instant Freq\", compute_entropy_of_instantaneous_frequency, real_part)\n",
    "            # add_feature(\"Envelope Variance\", compute_envelope_variance, real_part)\n",
    "            # add_feature(\"PAPR\", compute_papr, real_part)\n",
    "\n",
    "            # # Additional features for QAM16 vs QAM64 separation\n",
    "            add_feature(\"Avg Symbol Power\", lambda x: np.mean(np.abs(x)**2), complex_signal)\n",
    "            # add_feature(\"Magnitude Variance\", lambda x: np.var(np.abs(x)), complex_signal)\n",
    "            add_feature(\"PAPR\", lambda x: np.max(np.abs(x)**2) / np.mean(np.abs(x)**2), complex_signal)\n",
    "            add_feature(\"Kurtosis Magnitude\", lambda x: compute_kurtosis(np.abs(x)), complex_signal)\n",
    "            add_feature(\"Skewness Magnitude\", lambda x: compute_skewness(np.abs(x)), complex_signal)\n",
    "\n",
    "            \n",
    "            # Add SNR as a feature\n",
    "            feature_dict[\"SNR\"] = snr\n",
    "\n",
    "            # Append features and label\n",
    "            features.append(list(feature_dict.values()))\n",
    "            labels.append(mod_type)\n",
    "\n",
    "    return np.array(features), labels\n",
    "\n",
    "# Load dataset and preprocess\n",
    "with open(\"../RML2016.10a_dict.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f, encoding=\"latin1\")\n",
    "\n",
    "features, labels = extract_features(data)\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split dataset (Adjust as needed for validation)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, encoded_labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train model\n",
    "model = RandomForestModulationClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy, y_pred_test = model.evaluate(X_test, y_test)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Plot feature importance if applicable\n",
    "try:\n",
    "    feature_names = list(feature_dict.keys())\n",
    "    importances = model.model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.barh([feature_names[i] for i in indices], importances[indices], color='skyblue')\n",
    "    plt.xlabel(\"Feature Importance\")\n",
    "    plt.title(\"Feature Importance for Modulation Classification\")\n",
    "    plt.show()\n",
    "except AttributeError:\n",
    "    print(\"Feature importances are not available for this model.\")\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix for Modulation Classification\")\n",
    "plt.show()\n",
    "\n",
    "# Print Classification Report\n",
    "print(\"Classification Report for Modulation Types:\")\n",
    "print(classification_report(y_test, y_pred_test, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Evaluate accuracy for each SNR level\n",
    "unique_snrs = sorted(set(X_test[:, -1]))  # Get unique SNR levels from test set\n",
    "accuracy_per_snr = []\n",
    "\n",
    "for snr in unique_snrs:\n",
    "    # Select samples with the current SNR\n",
    "    snr_indices = np.where(X_test[:, -1] == snr)\n",
    "    X_snr = X_test[snr_indices]\n",
    "    y_snr = y_test[snr_indices]\n",
    "\n",
    "    # Predict and calculate accuracy\n",
    "    y_pred = model.predict(X_snr)\n",
    "    accuracy = accuracy_score(y_snr, y_pred)\n",
    "    accuracy_per_snr.append(accuracy * 100)  # Convert to percentage\n",
    "\n",
    "    print(f\"SNR: {snr} dB, Accuracy: {accuracy * 100:.2f}%\")\n",
    "# Plot Recognition Accuracy vs. SNR\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(unique_snrs, accuracy_per_snr, 'b-o', label='Recognition Accuracy')\n",
    "plt.xlabel(\"SNR (dB)\")\n",
    "plt.ylabel(\"Recognition Accuracy (%)\")\n",
    "plt.title(\"Recognition Accuracy vs. SNR for Modulation Classification\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.ylim(0, 100)\n",
    "plt.show()\n",
    "\n",
    "# Assuming SNR values are in the last column of X_test\n",
    "snr_column_index = -1  # Adjust this if SNR is in a different column\n",
    "\n",
    "# Find indices where SNR > 5\n",
    "snr_above_5_indices = np.where(X_test[:, snr_column_index] > 5)[0]\n",
    "X_test_snr_above_5 = X_test[snr_above_5_indices]\n",
    "y_test_snr_above_5 = y_test[snr_above_5_indices]\n",
    "\n",
    "# Make predictions on the SNR > 5 dB subset\n",
    "y_pred_snr_above_5 = model.predict(X_test_snr_above_5)\n",
    "\n",
    "# Plot confusion matrix for SNR > 5 dB\n",
    "conf_matrix_snr_above_5 = confusion_matrix(y_test_snr_above_5, y_pred_snr_above_5)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(conf_matrix_snr_above_5, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix for Modulation Classification (SNR > 5 dB)\")\n",
    "plt.show()\n",
    "\n",
    "# Print the classification report for SNR > 5 dB\n",
    "print(\"Classification Report for Modulation Types (SNR > 5 dB):\")\n",
    "print(classification_report(y_test_snr_above_5, y_pred_snr_above_5, target_names=label_encoder.classes_))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
